{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7530833,"sourceType":"datasetVersion","datasetId":4380873},{"sourceId":7530871,"sourceType":"datasetVersion","datasetId":4386246}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/lorentzyeung/a-langchain-openai-complete-tutorial-02?scriptVersionId=161982580\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# **A LangChain + OpenAI Complete Tutorial for Beginner - Lesson 2 Advanced Chatbot with RAG and Vector Databases**","metadata":{}},{"cell_type":"markdown","source":"For the full Lesson 2, please visit here:\n\nhttps://pub.towardsai.net/a-langchain-openai-complete-tutorial-for-beginner-lesson-2-advanced-chatbot-with-rag-and-vector-b6fe524909cb","metadata":{}},{"cell_type":"markdown","source":"## Content:\n\n1. **Introduction to Advanced Concepts**\n   - Brief overview of Retrieval-Augmented Generation (RAG)\n   - The role of vector databases in document management\n\n2. **Setting Up the Environment for Advanced Features**\n   - Installing additional libraries for RAG and vector databases\n\n3. **Loading and Preparing Documents**\n   - Utilizing loaders for different document types\n      - PDF,\n      - CSV,\n      - Wikipedia\n   - Splitting and processing documents for RAG\n      - Splitting text\n      - Loading and Splitting HTML\n\n4. **Implementing Vector Databases**\n   - Selecting the right vector database for your needs\n   - Selecting the Right Embeddings Model\n   - Load the PDF and Store it in RAG\n   - Utilizing a Vector Database in Retrieval-Augmented Generation\n\n5. **Integrating RAG with Vector Databases**\n   - Crafting Queries for RAG\n   - Querying and Retrieving Information\n\n6. **Conclusion and Further Exploration**\n   - Recap of the advanced features implemented\n   - Coming Up Next","metadata":{}},{"cell_type":"markdown","source":"In the lesson 1, you have learned the basics of building chatbot applications using LangChain, OpenAI, and Hugging Face. We started by setting up the environment and choosing the right language model. Then, we progressed to creating a simple chatbot, enhancing it with prompt templates for structured interactions. We also delved into the crucial aspects of managing chat model memory and introduced advanced features like Conversation Chains and Summary Memory.\n\nIn this lesson 2, we learn advanced system with RAG, and Loader. With RAG and Loader, your chatbot can tap into the external information or konwledge and supercharge the answers to your questions.","metadata":{}},{"cell_type":"markdown","source":"## 1. Introduction to Advanced Concepts\nRetrieval-Augmented Generation is a cutting-edge approach in AI, combining the power of language models with external knowledge sources. RAG enhances the capability of chatbots by allowing them to pull in information from a variety of documents, making responses more informative and contextually rich. This is particularily useful in commercial companies, e.g. creating a chatbot for client bases data retrieving.","metadata":{}},{"cell_type":"markdown","source":"## 2. Ensure the Environments","metadata":{}},{"cell_type":"markdown","source":"Like our previous tutorial, we will stick to our langchain-openai 0.0.5, langchain 0.1.4, and openai 1.10.0.","metadata":{}},{"cell_type":"code","source":"!pip install --quiet langchain-openai==0.0.5\n!pip install --quiet langchain==0.1.4\n!pip install --quiet langchain-community==0.0.16\n\n!pip install --quiet openai==1.10.0\n\n!pip install --upgrade --quiet  lark==1.1.9\n!pip install --upgrade --quiet  chromadb==0.4.22","metadata":{"execution":{"iopub.status.busy":"2024-02-01T19:45:53.514471Z","iopub.execute_input":"2024-02-01T19:45:53.514827Z","iopub.status.idle":"2024-02-01T19:47:18.135666Z","shell.execute_reply.started":"2024-02-01T19:45:53.514801Z","shell.execute_reply":"2024-02-01T19:47:18.134675Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\njupyterlab 4.0.11 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.2 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.8.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires kubernetes<27,>=8.0.0, but you have kubernetes 29.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import sys\nimport subprocess\nimport json\n\n# Function to get the version of a package using pip\ndef get_package_version(package_name):\n    result = subprocess.run([sys.executable, '-m', 'pip', 'list', '--format', 'json'], capture_output=True, text=True)\n    packages = json.loads(result.stdout)\n    for package in packages:\n        if package[\"name\"].lower() == package_name.lower():\n            return package[\"version\"]\n    return \"Package not found\"\n\n# Get versions\nlangchain_version = get_package_version(\"langchain\")\nlangchain_openai_version = get_package_version(\"langchain-openai\")\nlangchain_community_version = get_package_version(\"langchain-community\")\n\nopenai_version = get_package_version(\"openai\")\npython_version = sys.version\n\nlark_version = get_package_version(\"lark\")\nchromadb_version = get_package_version(\"chromadb\")\n\n\n# Display versions\nprint(f\"Langchain version: {langchain_version}\")\nprint(f\"langchain openai version: {langchain_openai_version}\")\nprint(f\"langchain-community version: {langchain_community_version}\")\nprint(f\"OpenAI version: {openai_version}\")\nprint(f\"Python version: {python_version}\")\nprint(f\"Lark version: {lark_version}\")\nprint(f\"Chromadb version: {chromadb_version}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-01T19:47:18.138412Z","iopub.execute_input":"2024-02-01T19:47:18.138682Z","iopub.status.idle":"2024-02-01T19:47:24.923495Z","shell.execute_reply.started":"2024-02-01T19:47:18.138659Z","shell.execute_reply":"2024-02-01T19:47:24.922939Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Langchain version: 0.1.4\nlangchain openai version: 0.0.5\nlangchain-community version: 0.0.16\nOpenAI version: 1.10.0\nPython version: 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:36:39) [GCC 12.3.0]\nLark version: 1.1.9\nChromadb version: 0.4.22\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 3. Loading and Preparing Documents\n","metadata":{}},{"cell_type":"markdown","source":"First let's load the necessary library from LangChain, and setup our chat model (ChatOpenAI) before loading our documents.","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append(\"/kaggle/input/api-py/\")\n#import api\n#openai_api_key = api.openai_api_key","metadata":{"execution":{"iopub.status.busy":"2024-02-01T19:48:14.077852Z","iopub.execute_input":"2024-02-01T19:48:14.078326Z","iopub.status.idle":"2024-02-01T19:48:14.082135Z","shell.execute_reply.started":"2024-02-01T19:48:14.078299Z","shell.execute_reply":"2024-02-01T19:48:14.081254Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from langchain.llms import OpenAI\nfrom langchain_openai import ChatOpenAI\n\n# Set your API Key from OpenAI\n# your api key should be something like this:\n# openai_api_key = 'sk-5Y9BbKFBbte5aghtOXRvT3BlbkFJLwwUvc4hjAf4YUw9KOabc'\nopenai_api_key = ''\n\nchat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, openai_api_key=openai_api_key)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T19:48:19.654615Z","iopub.execute_input":"2024-02-01T19:48:19.655028Z","iopub.status.idle":"2024-02-01T19:48:19.680246Z","shell.execute_reply.started":"2024-02-01T19:48:19.654994Z","shell.execute_reply":"2024-02-01T19:48:19.679481Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"If you haven't yet installed the pypdf library, install it now. Pypdf is a free and open-source pure-python PDF library capable of splitting, merging, cropping, and transforming the pages of PDF files.\n\nFor more detailed information, you are welcome to visit their official page. https://pypi.org/project/pypdf/. If you are only interested in RAG and creating chatbot, this is ignorable.","metadata":{}},{"cell_type":"code","source":"!pip install pypdf","metadata":{"execution":{"iopub.status.busy":"2024-02-01T19:48:19.681477Z","iopub.execute_input":"2024-02-01T19:48:19.681746Z","iopub.status.idle":"2024-02-01T19:48:29.569359Z","shell.execute_reply.started":"2024-02-01T19:48:19.681724Z","shell.execute_reply":"2024-02-01T19:48:29.568653Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pypdf in /opt/conda/lib/python3.10/site-packages (4.0.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from pypdf import PdfReader\n\nreader = PdfReader(\"/kaggle/input/langchain-openai-a-complete-tutorial/t-entz.pdf\")\nnumber_of_pages = len(reader.pages)\npage = reader.pages[0]\ntext = page.extract_text()\n\n# Load the document\nprint(text)\nprint(number_of_pages)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T19:48:29.570275Z","iopub.execute_input":"2024-02-01T19:48:29.570548Z","iopub.status.idle":"2024-02-01T19:48:29.763654Z","shell.execute_reply.started":"2024-02-01T19:48:29.570526Z","shell.execute_reply":"2024-02-01T19:48:29.762801Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"T-Entz  (pronounce: t-ants) TYRANT LIZARD T-Entz is a close rela=ve of T-Rex, it lives up to its reputa=on as one of the most admired no-eaters of all =me. Its powerful jaw had 2 teeth, each one about 0.5 inches long, and its smile was about three =mes more powerful than the Minions. Bite marks found on Triceratops fossils show that T-Entz could be playful, and its laughter remained in the fossil of trees. It could use its good sense of humour to melt the invisible walls between animals. It would have been able to scare oﬀ any other toxic animals, so the world was much beRer with it. We do not know whether T-Entz laughed alone or in packs, as no groups of skeletons have been found together.  LENGTH: 40 W DIET: water WHEN IT LIVED: Late Jurassic period FOUND IN: Hong Kong and the back of the Moon  Excerpt From Dic=onary of Dinosaurs By Lorentz Yeung This material is not protected by copyright. \n1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Actually LangChain has its own official pdf loader, and text loader. Showing you the pypdf reader is to verify the official pdf loader by LangChain can do the job exactly well.","metadata":{}},{"cell_type":"code","source":"from langchain.document_loaders import PyPDFLoader # this is for pdf\nfrom langchain.document_loaders import TextLoader # this is for txt file.\n\nreader = PyPDFLoader('/kaggle/input/langchain-openai-a-complete-tutorial/t-entz.pdf')\n# reader = TextLoader('t-entz.txt', encoding='utf-8')\n\n# Load the document\ndata = reader.load()\nprint(data[0])","metadata":{"execution":{"iopub.status.busy":"2024-02-01T19:48:29.766169Z","iopub.execute_input":"2024-02-01T19:48:29.766739Z","iopub.status.idle":"2024-02-01T19:48:29.935673Z","shell.execute_reply.started":"2024-02-01T19:48:29.766707Z","shell.execute_reply":"2024-02-01T19:48:29.934817Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"page_content='T-Entz  (pronounce: t-ants) TYRANT LIZARD T-Entz is a close rela=ve of T-Rex, it lives up to its reputa=on as one of the most admired no-eaters of all =me. Its powerful jaw had 2 teeth, each one about 0.5 inches long, and its smile was about three =mes more powerful than the Minions. Bite marks found on Triceratops fossils show that T-Entz could be playful, and its laughter remained in the fossil of trees. It could use its good sense of humour to melt the invisible walls between animals. It would have been able to scare oﬀ any other toxic animals, so the world was much beRer with it. We do not know whether T-Entz laughed alone or in packs, as no groups of skeletons have been found together.  LENGTH: 40 W DIET: water WHEN IT LIVED: Late Jurassic period FOUND IN: Hong Kong and the back of the Moon  Excerpt From Dic=onary of Dinosaurs By Lorentz Yeung This material is not protected by copyright. ' metadata={'source': '/kaggle/input/langchain-openai-a-complete-tutorial/t-entz.pdf', 'page': 0}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"See the results? They are basically the same. \n\nHow about CSV?","metadata":{}},{"cell_type":"code","source":"# Import library\nfrom langchain_community.document_loaders.csv_loader import CSVLoader\n\n# Create a document loader for fifa_countries_audience.csv\nreader = CSVLoader(file_path='/kaggle/input/langchain-openai-a-complete-tutorial/sample.csv')\n\n# Load the document\ndata = reader.load()\nprint(data[0])","metadata":{"execution":{"iopub.status.busy":"2024-02-01T19:48:29.936537Z","iopub.execute_input":"2024-02-01T19:48:29.93697Z","iopub.status.idle":"2024-02-01T19:48:29.947265Z","shell.execute_reply.started":"2024-02-01T19:48:29.93695Z","shell.execute_reply":"2024-02-01T19:48:29.946497Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"page_content='Component: Christmas Day\\nCoefficient: -6.52339e-13' metadata={'source': '/kaggle/input/langchain-openai-a-complete-tutorial/sample.csv', 'row': 0}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"How about webpages? There are tons of loader in LangChain, including pictures, BigQuery, Reddit, subtitle... etc.\nFeel free to check out the official page: https://python.langchain.com/docs/integrations/document_loaders/\n\nOur last example is to load the content from Wikipedia.\n","metadata":{}},{"cell_type":"code","source":"%pip install --upgrade --quiet  wikipedia","metadata":{"execution":{"iopub.status.busy":"2024-02-01T19:48:29.948275Z","iopub.execute_input":"2024-02-01T19:48:29.94857Z","iopub.status.idle":"2024-02-01T19:48:41.843968Z","shell.execute_reply.started":"2024-02-01T19:48:29.948544Z","shell.execute_reply":"2024-02-01T19:48:41.842856Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from langchain_community.document_loaders import WikipediaLoader\n\ndocs = WikipediaLoader(query=\"dragon ball z\", load_max_docs=2).load()\nlen(docs)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T19:48:41.84531Z","iopub.execute_input":"2024-02-01T19:48:41.845593Z","iopub.status.idle":"2024-02-01T19:48:43.838386Z","shell.execute_reply.started":"2024-02-01T19:48:41.845562Z","shell.execute_reply":"2024-02-01T19:48:43.83757Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}]},{"cell_type":"code","source":"docs[0].metadata  # meta-information of the Document","metadata":{"execution":{"iopub.status.busy":"2024-02-01T19:48:43.83927Z","iopub.execute_input":"2024-02-01T19:48:43.839605Z","iopub.status.idle":"2024-02-01T19:48:43.844614Z","shell.execute_reply.started":"2024-02-01T19:48:43.839586Z","shell.execute_reply":"2024-02-01T19:48:43.843867Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"{'title': 'Dragon Ball Z',\n 'summary': \"Dragon Ball Z is a Japanese anime television series produced by Toei Animation. Part of the Dragon Ball media franchise, it is the sequel to the 1986 Dragon Ball television series and adapts the latter 325 chapters of the original Dragon Ball manga series created by Akira Toriyama. The series aired in Japan on Fuji TV from April 1989 to January 1996, and was later dubbed for broadcast in at least 81 countries worldwide.Dragon Ball Z continues the adventures of Son Goku in his adult life as he and his companions defend the Earth against villains including aliens (Vegeta, Freeza), androids (Cell), and magical creatures (Majin Boo). At the same time, the story parallels the life of Goku's son, Gohan, as well as the development of his rivals, Piccolo and Vegeta.\\nDue to the success of the series in the United States, the manga chapters making up its story were initially released by Viz Media under the Dragon Ball Z title. The anime's popularity has also spawned various media and merchandise that has come to represent the majority of the material within the Dragon Ball franchise, including films, home video releases, soundtracks, trading cards, and video games. Dragon Ball Z remains a cultural icon through numerous adaptations and re-releases, including a remastered broadcast titled Dragon Ball Z Kai.\\nDragon Ball Z has since been followed by a sequel series titled Dragon Ball GT (1996–1997) and a midquel series titled Dragon Ball Super (2015–2018).\",\n 'source': 'https://en.wikipedia.org/wiki/Dragon_Ball_Z'}"},"metadata":{}}]},{"cell_type":"code","source":"docs[0].page_content[:400]  # a content of the Document","metadata":{"execution":{"iopub.status.busy":"2024-02-01T19:48:43.845437Z","iopub.execute_input":"2024-02-01T19:48:43.845661Z","iopub.status.idle":"2024-02-01T19:48:43.855388Z","shell.execute_reply.started":"2024-02-01T19:48:43.845641Z","shell.execute_reply":"2024-02-01T19:48:43.854733Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"'Dragon Ball Z is a Japanese anime television series produced by Toei Animation. Part of the Dragon Ball media franchise, it is the sequel to the 1986 Dragon Ball television series and adapts the latter 325 chapters of the original Dragon Ball manga series created by Akira Toriyama. The series aired in Japan on Fuji TV from April 1989 to January 1996, and was later dubbed for broadcast in at least '"},"metadata":{}}]},{"cell_type":"markdown","source":"### Splitting and processing documents for RAG\n\n#### Splitting text","metadata":{}},{"cell_type":"code","source":"# Import libary\nfrom langchain.text_splitter import CharacterTextSplitter\n\ndoc = 'Lorentz, is the English name of Pui Yeung, who is a data scientist. \\n Here is some statistics of it. \\n\\nIn 1939, unpaid Domestic Duties was the top reported job for people in the United Kingdom named Lorentz.'\nchunk_size = 30\nchunk_overlap = 3\nseparator = \"\\n\" # adding this as an additional to default\n\n# Create an instance of the splitter class\nsplitter = CharacterTextSplitter(\n    chunk_size=chunk_size,\n    chunk_overlap=chunk_overlap,\n    separator=separator\n    )\n\n# Split the document and print the chunks\ndocs = splitter.split_text(doc)\ndocs","metadata":{"execution":{"iopub.status.busy":"2024-02-01T19:48:43.857706Z","iopub.execute_input":"2024-02-01T19:48:43.858256Z","iopub.status.idle":"2024-02-01T19:48:43.866145Z","shell.execute_reply.started":"2024-02-01T19:48:43.858235Z","shell.execute_reply":"2024-02-01T19:48:43.865508Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"['Lorentz, is the English name of Pui Yeung, who is a data scientist.',\n 'Here is some statistics of it.',\n 'In 1939, unpaid Domestic Duties was the top reported job for people in the United Kingdom named Lorentz.']"},"metadata":{}}]},{"cell_type":"markdown","source":"### Loading and Splitting HTML","metadata":{}},{"cell_type":"markdown","source":"Let's split a html file. We are doing this exercise because very often we will face this need in real world.","metadata":{}},{"cell_type":"code","source":"!pip install --quiet unstructured","metadata":{"execution":{"iopub.status.busy":"2024-02-01T19:48:43.866992Z","iopub.execute_input":"2024-02-01T19:48:43.867606Z","iopub.status.idle":"2024-02-01T19:48:58.311312Z","shell.execute_reply.started":"2024-02-01T19:48:43.867576Z","shell.execute_reply":"2024-02-01T19:48:58.310304Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from langchain_community.document_loaders import UnstructuredHTMLLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\n# Load the HTML document into memory\n\nreader = UnstructuredHTMLLoader(\"/kaggle/input/langchain-openai-a-complete-tutorial/t-entz.html\")\ndoc = reader.load()\n\n# Define variables\nchunk_size = 200\nchunk_overlap = 50\n\n# Split the HTML\nsplitter = RecursiveCharacterTextSplitter(\n    chunk_size=chunk_size,\n    chunk_overlap=chunk_overlap,\n    separators=['.'])\n\ndocs = splitter.split_documents(doc) \ndocs","metadata":{"execution":{"iopub.status.busy":"2024-02-01T19:48:58.312653Z","iopub.execute_input":"2024-02-01T19:48:58.312981Z","iopub.status.idle":"2024-02-01T19:49:00.941943Z","shell.execute_reply.started":"2024-02-01T19:48:58.312952Z","shell.execute_reply":"2024-02-01T19:49:00.941165Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"[Document(page_content='T-Entz\\n\\n(tie-ants) TYRANT LIZARD\\n\\nT-Entz is a close relative of T-Rex, it lives up to its reputation as one of the most admired no-eaters of all time. Its powerful jaw had 2 teeth, each one about 0', metadata={'source': '/kaggle/input/langchain-openai-a-complete-tutorial/t-entz.html'}),\n Document(page_content='. Its powerful jaw had 2 teeth, each one about 0.5 inches long, and its smile was about three times more powerful than the Minions', metadata={'source': '/kaggle/input/langchain-openai-a-complete-tutorial/t-entz.html'}),\n Document(page_content='. Bite marks found on Triceratops fossils show that T-Entz could be playful, and its laughter remained in the fossil of trees', metadata={'source': '/kaggle/input/langchain-openai-a-complete-tutorial/t-entz.html'}),\n Document(page_content='. It could use its good sense of humour to melt the invisible walls between animals. It would have been able to scare off any other toxic animals, so the world was much better with it', metadata={'source': '/kaggle/input/langchain-openai-a-complete-tutorial/t-entz.html'}),\n Document(page_content='. We do not know whether T-Entz laughed alone or in packs, as no groups of skeletons have been found together', metadata={'source': '/kaggle/input/langchain-openai-a-complete-tutorial/t-entz.html'}),\n Document(page_content='.\\n\\nLENGTH: 40 ft\\n\\nDIET: water\\n\\nWHEN IT LIVED: Late Jurassic period\\n\\nFOUND IN: Hong Kong and the back of the Moon\\n\\nExcerpt From\\n\\nDictionary of Dinosaurs\\n\\nBy Lorentz Yeung', metadata={'source': '/kaggle/input/langchain-openai-a-complete-tutorial/t-entz.html'})]"},"metadata":{}}]},{"cell_type":"markdown","source":"The function works with similar logic, it split according to the chunk size and marks specified, while prioritizing the natural breaks and pauses.","metadata":{}},{"cell_type":"markdown","source":"## 4. Implementing RAG with Vector Databases for Document Management\n\nTo make it easier to find and use parts of documents in a system called RAG (Retrieval-Augmented Generation), we turn these document parts into special coded forms. Each part gets a number-based code that sums up what it's about and how important it is. \n\nIt's really important to use this special kind of database, a vector database, to keep and organize these document parts in a smart way. This database sorts them by what they're about and their deeper meaning. It helps to quickly find and evaluate these parts, checking how relevant they are based on how similar their codes are, and then using them in the system's responses.\n","metadata":{}},{"cell_type":"markdown","source":"### Load the PDF and Store it in RAG","metadata":{}},{"cell_type":"markdown","source":"Let's get our hands dirty now. First we import the required library as usual.","metadata":{}},{"cell_type":"code","source":"# Prepare the documents and vector database\nfrom langchain.document_loaders import PyPDFLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_community.vectorstores import Chroma","metadata":{"execution":{"iopub.status.busy":"2024-02-01T19:49:00.942855Z","iopub.execute_input":"2024-02-01T19:49:00.943076Z","iopub.status.idle":"2024-02-01T19:49:00.953377Z","shell.execute_reply.started":"2024-02-01T19:49:00.943056Z","shell.execute_reply":"2024-02-01T19:49:00.952711Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"Then we load the pdf, and split it and then stor it in dataset called \"doc\".","metadata":{}},{"cell_type":"code","source":"openai_api_key= openai_api_key\nloader = PyPDFLoader('/kaggle/input/langchain-openai-a-complete-tutorial/t-entz.pdf')\ntext = loader.load()\nchunk_size = 20\nchunk_overlap = 5\n\n# Split the pdf\nsplitter = RecursiveCharacterTextSplitter(\n    chunk_size = chunk_size,\n    chunk_overlap = chunk_overlap,\n    separators=['.']\n    )\ndoc = splitter.split_documents(text)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T19:49:00.954507Z","iopub.execute_input":"2024-02-01T19:49:00.954965Z","iopub.status.idle":"2024-02-01T19:49:00.994298Z","shell.execute_reply.started":"2024-02-01T19:49:00.954943Z","shell.execute_reply":"2024-02-01T19:49:00.993568Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"Then store it into our vector database, which will then observable in your local working directory named \"chroma\".","metadata":{}},{"cell_type":"code","source":"# Use the OpenAI embeddings method to embed \"meaning\" into the text\nembedding = OpenAIEmbeddings(openai_api_key=openai_api_key)\n# embedding = OpenAIEmbeddings(openai_api_key=openai_api_key, model_name='text-embedding-3-small')\n\npersist_directory = \"embedding/chroma\"\n\n# Create a Chroma vector database for the current states after embedding\nvectordb = Chroma(\n    persist_directory = persist_directory,\n    embedding_function = embedding)\nvectordb.persist() #  save its current states and any data it holds to the specified directory (embedding/chroma/).\n# now you will see a folder named embedding in your working directory.","metadata":{"execution":{"iopub.status.busy":"2024-02-01T19:49:00.995951Z","iopub.execute_input":"2024-02-01T19:49:00.996275Z","iopub.status.idle":"2024-02-01T19:49:02.376836Z","shell.execute_reply.started":"2024-02-01T19:49:00.996248Z","shell.execute_reply":"2024-02-01T19:49:02.376009Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"By persisting the state of the vector database, we ensure that the data and settings don't get lost when the program is closed. This way, everything stays the same when you use the program again later. This is really important in situations where getting the database ready or filling it up takes a lot of computer power or time.","metadata":{}},{"cell_type":"code","source":"# store the db into the same folder. You will see sqlite3 and other files bin files now.\ndatabase = Chroma.from_documents(doc, embedding=embedding, persist_directory = persist_directory)\ndatabase","metadata":{"execution":{"iopub.status.busy":"2024-02-01T19:49:02.389045Z","iopub.execute_input":"2024-02-01T19:49:02.390024Z","iopub.status.idle":"2024-02-01T19:49:04.009949Z","shell.execute_reply.started":"2024-02-01T19:49:02.389988Z","shell.execute_reply":"2024-02-01T19:49:04.00917Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"<langchain_community.vectorstores.chroma.Chroma at 0x7a3e55b32230>"},"metadata":{}}]},{"cell_type":"markdown","source":"## 5. Integrating RAG with Vector Databases\n### Crafting Queries for RAG","metadata":{}},{"cell_type":"code","source":"from langchain.chains import RetrievalQA\nfrom langchain_openai import ChatOpenAI\n\nopenai_api_key = openai_api_key\nvectordb2 = Chroma(persist_directory = persist_directory, embedding_function=embedding)\nvectordb2.get()['documents']\n","metadata":{"execution":{"iopub.status.busy":"2024-02-01T19:49:04.01107Z","iopub.execute_input":"2024-02-01T19:49:04.01161Z","iopub.status.idle":"2024-02-01T19:49:05.411382Z","shell.execute_reply.started":"2024-02-01T19:49:04.011585Z","shell.execute_reply":"2024-02-01T19:49:05.410383Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"['T-Entz  (pronounce: t-ants) TYRANT LIZARD T-Entz is a close rela=ve of T-Rex, it lives up to its reputa=on as one of the most admired no-eaters of all =me',\n '. Its powerful jaw had 2 teeth, each one about 0',\n '.5 inches long, and its smile was about three =mes more powerful than the Minions',\n '. Bite marks found on Triceratops fossils show that T-Entz could be playful, and its laughter remained in the fossil of trees',\n '. It could use its good sense of humour to melt the invisible walls between animals',\n '. It would have been able to scare oﬀ any other toxic animals, so the world was much beRer with it',\n '. We do not know whether T-Entz laughed alone or in packs, as no groups of skeletons have been found together',\n '.  LENGTH: 40 W DIET: water WHEN IT LIVED: Late Jurassic period FOUND IN: Hong Kong and the back of the Moon  Excerpt From Dic=onary of Dinosaurs By Lorentz Yeung This material is not protected by copyright',\n '.']"},"metadata":{}}]},{"cell_type":"markdown","source":"Let's test if RetrievalQA have connected LLM with our own data. T-Entz is a term i made up by myself. I just mix up T-Rex with my name nickname Entz. Therefore GPT model has no where to know it but from my t-entz.pdf. If our model knows what is T-Entz, then our modelling is successful.","metadata":{}},{"cell_type":"code","source":"retriever = vectordb2.as_retriever() # search_kwargs={\"k\": 4}\n\nqa = RetrievalQA.from_chain_type(ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, openai_api_key=openai_api_key), \n                                 chain_type=\"stuff\",\n                                 retriever=retriever)\n# Run the chain on the query provided\nquery = \"what is T-entz?\"\nqa(query)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T19:49:05.412491Z","iopub.execute_input":"2024-02-01T19:49:05.412772Z","iopub.status.idle":"2024-02-01T19:49:07.692229Z","shell.execute_reply.started":"2024-02-01T19:49:05.41275Z","shell.execute_reply":"2024-02-01T19:49:07.691239Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n  warn_deprecated(\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"{'query': 'what is T-entz?',\n 'result': 'T-Entz is a dinosaur, specifically a close relative of the T-Rex. It is known for being a fearsome predator and one of the most admired carnivores of its time.'}"},"metadata":{}}]},{"cell_type":"markdown","source":"## 6. Conclusion\n### Recap of the advanced features implemented\nIn this second tutorial of our series, we dove into the more advanced aspects of chatbot development, exploring the integration of Retrieval-Augmented Generation (RAG) with vector databases. This journey has equipped us with valuable insights and skills essential for creating sophisticated and knowledgeable chatbots.\n\nWe encourage you to continue experimenting, exploring, and pushing the boundaries of what you can achieve with LangChain, OpenAI, and Hugging Face. The field of chatbot development is ever-evolving, and staying at the forefront of these advancements will ensure your chatbots are not just functional, but truly groundbreaking.\n\n### Coming Up Next\nIn the next lesson, we will learn LCEL. It simplifies the construction of complex chains from basic components. It is particularly useful for integrating external data sources with LLMs through a process like RetrievalQA, facilitating efficient data retrieval and interaction within these models. Stay tunned!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}